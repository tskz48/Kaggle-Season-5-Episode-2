{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id         Brand Material    Size  Compartments  \\\n",
      "0            0      Jansport  Leather  Medium           7.0   \n",
      "1            1      Jansport   Canvas   Small          10.0   \n",
      "2            2  Under Armour  Leather   Small           2.0   \n",
      "3            3          Nike    Nylon   Small           8.0   \n",
      "4            4        Adidas   Canvas  Medium           1.0   \n",
      "...        ...           ...      ...     ...           ...   \n",
      "299995  299995        Adidas  Leather   Small           9.0   \n",
      "299996  299996      Jansport  Leather   Large           6.0   \n",
      "299997  299997          Puma   Canvas   Large           9.0   \n",
      "299998  299998        Adidas    Nylon   Small           1.0   \n",
      "299999  299999  Under Armour   Canvas   Small           2.0   \n",
      "\n",
      "       Laptop Compartment Waterproof      Style  Color  Weight Capacity (kg)  \n",
      "0                     Yes         No       Tote  Black             11.611723  \n",
      "1                     Yes        Yes  Messenger  Green             27.078537  \n",
      "2                     Yes         No  Messenger    Red             16.643760  \n",
      "3                     Yes         No  Messenger  Green             12.937220  \n",
      "4                     Yes        Yes  Messenger  Green             17.749338  \n",
      "...                   ...        ...        ...    ...                   ...  \n",
      "299995                 No         No       Tote   Blue             12.730812  \n",
      "299996                 No        Yes       Tote   Blue             26.633182  \n",
      "299997                Yes        Yes   Backpack   Pink             11.898250  \n",
      "299998                 No        Yes       Tote   Pink              6.175738  \n",
      "299999                 No        Yes   Backpack  Black             18.568865  \n",
      "\n",
      "[300000 rows x 10 columns]\n",
      "0         112.15875\n",
      "1          68.88056\n",
      "2          39.17320\n",
      "3          80.60793\n",
      "4          86.02312\n",
      "            ...    \n",
      "299995    129.99749\n",
      "299996     19.85819\n",
      "299997    111.41364\n",
      "299998    115.89080\n",
      "299999     26.72762\n",
      "Name: Price, Length: 300000, dtype: float64\n",
      "id                        int64\n",
      "Brand                    object\n",
      "Material                 object\n",
      "Size                     object\n",
      "Compartments            float64\n",
      "Laptop Compartment       object\n",
      "Waterproof               object\n",
      "Style                    object\n",
      "Color                    object\n",
      "Weight Capacity (kg)    float64\n",
      "Price                   float64\n",
      "dtype: object\n",
      "id                         0\n",
      "Brand                   9705\n",
      "Material                8347\n",
      "Size                    6595\n",
      "Compartments               0\n",
      "Laptop Compartment      7444\n",
      "Waterproof              7050\n",
      "Style                   7970\n",
      "Color                   9950\n",
      "Weight Capacity (kg)     138\n",
      "Price                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_test = pd.read_csv(\"./train.csv\")\n",
    "X_train = df_train.drop(columns=['Price'])\n",
    "y_train = df_train['Price']\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "# X_test= df_test.drop(columns=['Price'])\n",
    "# y_test= df_test.drop(columns=['Price'])\n",
    "print(df_train.dtypes)\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "[''].fillna([''].median(), inplace=True)\n",
    "[''].fillna([''].median(), inplace=True)\n",
    "[''].fillna([''].median(), inplace=True)\n",
    "[''].fillna([''].median(), inplace=True)\n",
    "def impute_categorical_uniform(df, column):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a categorical column using a uniform distribution.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Input dataframe.\n",
    "    column (str): Column name to impute.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with imputed values.\n",
    "    \"\"\"\n",
    "    # Find unique categories (excluding NaN)\n",
    "    unique_categories = df[column].dropna().unique()\n",
    "    \n",
    "    # Count missing values\n",
    "    num_missing = df[column].isna().sum()\n",
    "    \n",
    "    # If there are missing values, sample from the unique categories\n",
    "    if num_missing > 0:\n",
    "        imputed_values = np.random.choice(unique_categories, size=num_missing, replace=True)\n",
    "        \n",
    "        # Assign these values to missing spots\n",
    "        df.loc[df[column].isna(), column] = imputed_values\n",
    "\n",
    "\n",
    "        method == \"probability\":\n",
    "                # Sample based on observed category probabilities\n",
    "                category_probs = df_copy[column].value_counts(normalize=True)\n",
    "                imputed_values = np.random.choice(category_probs.index, size=num_missing, p=category_probs.values)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train=impute_categorical_uniform(X_train, columns=[['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style', 'Color', 'Size']], method=\"probability\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "X_encoded = encoder.fit_transform(X_train[['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']])\n",
    "\n",
    "# Convert to a DataFrame\n",
    "encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Drop original categorical columns from X_train\n",
    "X_train = X_train.drop(columns=['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style', 'Color'])\n",
    "\n",
    "# Merge the transformed data back\n",
    "X_train = pd.concat([X_train, encoded_df], axis=1)\n",
    "encoder2 = LabelEncoder()\n",
    "X_train['Size'] = encoder2.fit_transform(X_train['Size'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sample dataset (Replace with your actual dataset)\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'epochs': [50, 100, 200],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "# Define StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid Search with StratifiedKFold\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Store validation scores\n",
    "val_accuracies = []\n",
    "\n",
    "# Define function to build a model\n",
    "def build_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Perform Stratified K-Fold on the training data\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    print(f\"\\nTraining Fold {fold+1}/{5}...\")\n",
    "\n",
    "    # Use `.iloc` for Pandas DataFrames/Series\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # Build and train the model\n",
    "    model = build_model(X_train.shape[1])\n",
    "    model.fit(X_tr, y_tr, epochs=10, batch_size=32, verbose=0, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate on validation fold\n",
    "    y_val_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "    fold_acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracies.append(fold_acc)\n",
    "    print(f\"Fold {fold+1} Accuracy: {fold_acc:.4f}\")\n",
    "\n",
    "# Print validation performance\n",
    "print(f\"\\nMean Validation Accuracy: {np.mean(val_accuracies):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(val_accuracies):.4f}\")\n",
    "\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(1)  # Single neuron for price prediction (regression)\n",
    "# ])\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# # Training the model\n",
    "# history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# # Evaluating the model\n",
    "# loss, mae = model.evaluate(X_test, y_test)\n",
    "# print(f'Test Mean Absolute Error: {mae:.2f}')\n",
    "\n",
    "# # Predicting on test data\n",
    "# predictions = model.predict(X_test[:5])\n",
    "# print(\"Predicted Prices:\", predictions.flatten())\n",
    "# print(\"Actual Prices:\", y_test[:5].values)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
