{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id         Brand Material    Size  Compartments  \\\n",
      "0            0      Jansport  Leather  Medium           7.0   \n",
      "1            1      Jansport   Canvas   Small          10.0   \n",
      "2            2  Under Armour  Leather   Small           2.0   \n",
      "3            3          Nike    Nylon   Small           8.0   \n",
      "4            4        Adidas   Canvas  Medium           1.0   \n",
      "...        ...           ...      ...     ...           ...   \n",
      "299995  299995        Adidas  Leather   Small           9.0   \n",
      "299996  299996      Jansport  Leather   Large           6.0   \n",
      "299997  299997          Puma   Canvas   Large           9.0   \n",
      "299998  299998        Adidas    Nylon   Small           1.0   \n",
      "299999  299999  Under Armour   Canvas   Small           2.0   \n",
      "\n",
      "       Laptop Compartment Waterproof      Style  Color  Weight Capacity (kg)  \n",
      "0                     Yes         No       Tote  Black             11.611723  \n",
      "1                     Yes        Yes  Messenger  Green             27.078537  \n",
      "2                     Yes         No  Messenger    Red             16.643760  \n",
      "3                     Yes         No  Messenger  Green             12.937220  \n",
      "4                     Yes        Yes  Messenger  Green             17.749338  \n",
      "...                   ...        ...        ...    ...                   ...  \n",
      "299995                 No         No       Tote   Blue             12.730812  \n",
      "299996                 No        Yes       Tote   Blue             26.633182  \n",
      "299997                Yes        Yes   Backpack   Pink             11.898250  \n",
      "299998                 No        Yes       Tote   Pink              6.175738  \n",
      "299999                 No        Yes   Backpack  Black             18.568865  \n",
      "\n",
      "[300000 rows x 10 columns]\n",
      "0         112.15875\n",
      "1          68.88056\n",
      "2          39.17320\n",
      "3          80.60793\n",
      "4          86.02312\n",
      "            ...    \n",
      "299995    129.99749\n",
      "299996     19.85819\n",
      "299997    111.41364\n",
      "299998    115.89080\n",
      "299999     26.72762\n",
      "Name: Price, Length: 300000, dtype: float64\n",
      "id                        int64\n",
      "Brand                    object\n",
      "Material                 object\n",
      "Size                     object\n",
      "Compartments            float64\n",
      "Laptop Compartment       object\n",
      "Waterproof               object\n",
      "Style                    object\n",
      "Color                    object\n",
      "Weight Capacity (kg)    float64\n",
      "Price                   float64\n",
      "dtype: object\n",
      "id                         0\n",
      "Brand                   9705\n",
      "Material                8347\n",
      "Size                    6595\n",
      "Compartments               0\n",
      "Laptop Compartment      7444\n",
      "Waterproof              7050\n",
      "Style                   7970\n",
      "Color                   9950\n",
      "Weight Capacity (kg)     138\n",
      "Price                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_test = pd.read_csv(\"./train.csv\")\n",
    "X_train = df_train.drop(columns=['Price'])\n",
    "y_train = df_train['Price']\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "# X_test= df_test.drop(columns=['Price'])\n",
    "# y_test= df_test.drop(columns=['Price'])\n",
    "print(df_train.dtypes)\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "# X_train['Compartments'].fillna(X_train['Compartments'].median(), inplace=True)\n",
    "# X_train['Weight Capacity'].fillna(X_train['Weight Capacity'].median(), inplace=True)\n",
    "# def impute_categorical_uniform(df, columns):\n",
    "#     \"\"\"\n",
    "#     Imputes missing values in a categorical column using a uniform distribution.\n",
    "    \n",
    "#     Args:\n",
    "#     df (pd.DataFrame): Input dataframe.\n",
    "#     column (str): Column name to impute.\n",
    "\n",
    "#     Returns:\n",
    "#     pd.DataFrame: Dataframe with imputed values.\n",
    "#     \"\"\"\n",
    "#     df_copy = df.copy()\n",
    "#     for column in columns:\n",
    "#         # Find unique categories (excluding NaN)\n",
    "        \n",
    "#     # Find unique categories (excluding NaN)\n",
    "#         unique_categories = df[column].dropna().unique()\n",
    "    \n",
    "#     # Count missing values\n",
    "#         num_missing = df[column].isna().sum()\n",
    "    \n",
    "#     # If there are missing values, sample from the unique categories\n",
    "#         if num_missing > 0:\n",
    "#             imputed_values = np.random.choice(unique_categories, size=num_missing, replace=True)\n",
    "        \n",
    "#         # Assign these values to missing spots\n",
    "#             df.loc[df[column].isna(), column] = imputed_values\n",
    "\n",
    "#                 # Sample based on observed category probabilities\n",
    "#             category_probs = df_copy[column].value_counts(normalize=True)\n",
    "#             imputed_values = np.random.choice(category_probs.index, size=num_missing, p=category_probs.values)\n",
    "#             df_copy.loc[df_copy[column].isna(), column] = imputed_values\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train=impute_categorical_uniform(X_train, columns=[['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style', 'Color', 'Size']], method=\"probability\")\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "# X_encoded = encoder.fit_transform(X_train[['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']])\n",
    "\n",
    "# # Convert to a DataFrame\n",
    "# encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# # Drop original categorical columns from X_train\n",
    "# X_train = X_train.drop(columns=['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style', 'Color'])\n",
    "\n",
    "# # Merge the transformed data back\n",
    "# X_train = pd.concat([X_train, encoded_df], axis=1)\n",
    "# encoder2 = LabelEncoder()\n",
    "# X_train['Size'] = encoder2.fit_transform(X_train['Size'])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Sample dataset (Replace with your actual dataset)\n",
    "\n",
    "# # Define Stratified K-Fold\n",
    "\n",
    "\n",
    "# def build_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#         keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "#         keras.layers.Dense(32, activation='relu'),\n",
    "#         keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='mse', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# keras_estimator = KerasRegressor(build_fn=build_model, verbose=0)\n",
    "\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.001, 0.01, 0.1],\n",
    "#     'dropout_rate': [0.2, 0.3, 0.5],\n",
    "#     'epochs': [50, 100, 200],\n",
    "#     'batch_size': [32, 64]\n",
    "# }\n",
    "\n",
    "# # Define StratifiedKFold\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Grid Search with StratifiedKFold\n",
    "# grid = GridSearchCV(estimator=keras_estimator, param_grid=param_grid, cv=cv, scoring='neg_root_mean_squared_error'', n_jobs=-1)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# # Define function to build a model\n",
    "\n",
    "# # Print validation performance\n",
    "\n",
    "# # # Training the model\n",
    "# # # Evaluating the model\n",
    "# # # Predicting on test data\n",
    "\n",
    "best_params = grid_result.best_params_\n",
    "final_model = build_model(input_dim=X_train.shape[1], \n",
    "                          learning_rate=best_params['learning_rate'], \n",
    "                          dropout_rate=best_params['dropout_rate'])\n",
    "\n",
    "final_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "test_loss, test_RMSE = final_model.evaluate(X_test, y_test)\n",
    "print(f\"Final Test Root Mean Squared Error (RMSE): {test_RMSE:.4f}\")\n",
    "\n",
    "\n",
    "# Evaluate the final model on test data\n",
    "y_test_pred = final_model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
