{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tskz48/anaconda3/envs/VSCode/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id         Brand Material    Size  Compartments  \\\n",
      "0            0      Jansport  Leather  Medium           7.0   \n",
      "1            1      Jansport   Canvas   Small          10.0   \n",
      "2            2  Under Armour  Leather   Small           2.0   \n",
      "3            3          Nike    Nylon   Small           8.0   \n",
      "4            4        Adidas   Canvas  Medium           1.0   \n",
      "...        ...           ...      ...     ...           ...   \n",
      "299995  299995        Adidas  Leather   Small           9.0   \n",
      "299996  299996      Jansport  Leather   Large           6.0   \n",
      "299997  299997          Puma   Canvas   Large           9.0   \n",
      "299998  299998        Adidas    Nylon   Small           1.0   \n",
      "299999  299999  Under Armour   Canvas   Small           2.0   \n",
      "\n",
      "       Laptop Compartment Waterproof      Style  Color  Weight Capacity (kg)  \n",
      "0                     Yes         No       Tote  Black             11.611723  \n",
      "1                     Yes        Yes  Messenger  Green             27.078537  \n",
      "2                     Yes         No  Messenger    Red             16.643760  \n",
      "3                     Yes         No  Messenger  Green             12.937220  \n",
      "4                     Yes        Yes  Messenger  Green             17.749338  \n",
      "...                   ...        ...        ...    ...                   ...  \n",
      "299995                 No         No       Tote   Blue             12.730812  \n",
      "299996                 No        Yes       Tote   Blue             26.633182  \n",
      "299997                Yes        Yes   Backpack   Pink             11.898250  \n",
      "299998                 No        Yes       Tote   Pink              6.175738  \n",
      "299999                 No        Yes   Backpack  Black             18.568865  \n",
      "\n",
      "[300000 rows x 10 columns]\n",
      "0         112.15875\n",
      "1          68.88056\n",
      "2          39.17320\n",
      "3          80.60793\n",
      "4          86.02312\n",
      "            ...    \n",
      "299995    129.99749\n",
      "299996     19.85819\n",
      "299997    111.41364\n",
      "299998    115.89080\n",
      "299999     26.72762\n",
      "Name: Price, Length: 300000, dtype: float64\n",
      "id                        int64\n",
      "Brand                    object\n",
      "Material                 object\n",
      "Size                     object\n",
      "Compartments            float64\n",
      "Laptop Compartment       object\n",
      "Waterproof               object\n",
      "Style                    object\n",
      "Color                    object\n",
      "Weight Capacity (kg)    float64\n",
      "Price                   float64\n",
      "dtype: object\n",
      "id                         0\n",
      "Brand                   9705\n",
      "Material                8347\n",
      "Size                    6595\n",
      "Compartments               0\n",
      "Laptop Compartment      7444\n",
      "Waterproof              7050\n",
      "Style                   7970\n",
      "Color                   9950\n",
      "Weight Capacity (kg)     138\n",
      "Price                      0\n",
      "dtype: int64\n",
      "Compartments: 0 outliers detected.\n",
      "Weight Capacity (kg): 0 outliers detected.\n",
      "Price: 0 outliers detected.\n",
      "            id  Size  Compartments  Weight Capacity (kg)  Brand_Jansport  \\\n",
      "0            0     1      0.538408             -0.921466             1.0   \n",
      "1            1     2      1.576198              1.299086             1.0   \n",
      "2            2     2     -1.191240             -0.199023             0.0   \n",
      "3            3     2      0.884338             -0.731166             0.0   \n",
      "4            4     1     -1.537170             -0.040296             0.0   \n",
      "...        ...   ...           ...                   ...             ...   \n",
      "299995  299995     2      1.230268             -0.760800             0.0   \n",
      "299996  299996     0      0.192479              1.235147             1.0   \n",
      "299997  299997     0      1.230268             -0.880330             0.0   \n",
      "299998  299998     2     -1.537170             -1.701904             0.0   \n",
      "299999  299999     2     -1.191240              0.077363             0.0   \n",
      "\n",
      "        Brand_Nike  Brand_Puma  Brand_Under Armour  Material_Leather  \\\n",
      "0              0.0         0.0                 0.0               1.0   \n",
      "1              0.0         0.0                 0.0               0.0   \n",
      "2              0.0         0.0                 1.0               1.0   \n",
      "3              1.0         0.0                 0.0               0.0   \n",
      "4              0.0         0.0                 0.0               0.0   \n",
      "...            ...         ...                 ...               ...   \n",
      "299995         0.0         0.0                 0.0               1.0   \n",
      "299996         0.0         0.0                 0.0               1.0   \n",
      "299997         0.0         1.0                 0.0               0.0   \n",
      "299998         0.0         0.0                 0.0               0.0   \n",
      "299999         0.0         0.0                 1.0               0.0   \n",
      "\n",
      "        Material_Nylon  Material_Polyester  Laptop Compartment_Yes  \\\n",
      "0                  0.0                 0.0                     1.0   \n",
      "1                  0.0                 0.0                     1.0   \n",
      "2                  0.0                 0.0                     1.0   \n",
      "3                  1.0                 0.0                     1.0   \n",
      "4                  0.0                 0.0                     1.0   \n",
      "...                ...                 ...                     ...   \n",
      "299995             0.0                 0.0                     0.0   \n",
      "299996             0.0                 0.0                     0.0   \n",
      "299997             0.0                 0.0                     1.0   \n",
      "299998             1.0                 0.0                     0.0   \n",
      "299999             0.0                 0.0                     0.0   \n",
      "\n",
      "        Waterproof_Yes  Style_Messenger  Style_Tote  \n",
      "0                  0.0              0.0         1.0  \n",
      "1                  1.0              1.0         0.0  \n",
      "2                  0.0              1.0         0.0  \n",
      "3                  0.0              1.0         0.0  \n",
      "4                  1.0              1.0         0.0  \n",
      "...                ...              ...         ...  \n",
      "299995             0.0              0.0         1.0  \n",
      "299996             1.0              0.0         1.0  \n",
      "299997             1.0              0.0         0.0  \n",
      "299998             1.0              0.0         1.0  \n",
      "299999             1.0              0.0         0.0  \n",
      "\n",
      "[300000 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.pruners import HyperbandPruner\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "X_train = df_train.drop(columns=['Price'])\n",
    "y_train = df_train['Price']\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "X_test= df_test\n",
    "print(df_train.dtypes)\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "X_train['Compartments'].fillna(X_train['Compartments'].median(), inplace=True)\n",
    "X_train['Weight Capacity (kg)'].fillna(X_train['Weight Capacity (kg)'].median(), inplace=True)\n",
    "def impute_categorical_uniform(df, columns):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a categorical column using a uniform distribution.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Input dataframe.\n",
    "    column (str): Column name to impute.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with imputed values.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for column in columns:\n",
    "        # Find unique categories (excluding NaN)\n",
    "        \n",
    "        # Find unique categories (excluding NaN)\n",
    "        #unique_categories = df[column].dropna().unique()\n",
    "    \n",
    "    # Count missing values\n",
    "        num_missing = df[column].isna().sum()\n",
    "    \n",
    "    # If there are missing values, sample from the unique categories\n",
    "        if num_missing > 0:\n",
    "\n",
    "\n",
    "                # Sample based on observed category probabilities\n",
    "            category_probs = df_copy[column].value_counts(normalize=True)\n",
    "            imputed_values = np.random.choice(category_probs.index, size=num_missing, p=category_probs.values)\n",
    "            df_copy.loc[df_copy[column].isna(), column] = imputed_values\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train=impute_categorical_uniform(X_train, columns=['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style', 'Color', 'Size'])\n",
    "\n",
    "\n",
    "\n",
    "def detect_outliers_iqr(df, columns):\n",
    "    \"\"\"\n",
    "    Detects outliers using the IQR method.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Input dataframe.\n",
    "    columns (list): List of numerical columns to check.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with outlier information.\n",
    "    \"\"\"\n",
    "    df_outliers = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        Q1 = df_outliers[col].quantile(0.25)\n",
    "        Q3 = df_outliers[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Detect outliers\n",
    "        outliers = df_outliers[(df_outliers[col] < lower_bound) | (df_outliers[col] > upper_bound)]\n",
    "        print(f\"{col}: {len(outliers)} outliers detected.\")\n",
    "    \n",
    "    return df_outliers\n",
    "\n",
    "# Detect outliers in numerical columns\n",
    "numerical_cols = ['Compartments', 'Weight Capacity (kg)']\n",
    "\n",
    "detect_outliers_iqr(X_train, numerical_cols)\n",
    "\n",
    "detect_outliers_iqr(pd.DataFrame(y_train, columns=['Price']), ['Price'])\n",
    "# Initialize Isolation Forest\n",
    "# iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "\n",
    "# # Fit on training data (excluding target variable)\n",
    "# outliers = iso_forest.fit_predict(X_train)  # Returns 1 (normal) or -1 (outlier)\n",
    "\n",
    "# # Remove detected outliers\n",
    "# X_train_filtered = X_train[outliers == 1]\n",
    "# y_train_filtered = y_train[outliers == 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_standardize = ['Compartments', 'Weight Capacity (kg)'] \n",
    "X_train[columns_to_standardize] = scaler.fit_transform(X_train[columns_to_standardize])\n",
    "X_train.drop('Color',axis=1,inplace=True)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "X_encoded = encoder.fit_transform(X_train[['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style']])\n",
    "\n",
    "# Convert to a DataFrame\n",
    "encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Drop original categorical columns from X_train\n",
    "X_train = X_train.drop(columns=['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style'])\n",
    "# Merge the transformed data back\n",
    "X_train = pd.concat([X_train, encoded_df], axis=1)\n",
    "encoder2 = LabelEncoder()\n",
    "X_train['Size'] = encoder2.fit_transform(X_train['Size'])\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "GPU enabled: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "\n",
      " Training Fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 13:09:18.119401: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-11 13:09:18.119513: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 26ms/step - loss: 7658.2139 - root_mean_squared_error: 82.0833 - val_loss: 3454.4626 - val_root_mean_squared_error: 58.7685\n",
      "Epoch 2/100\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - loss: 2200.7046 - root_mean_squared_error: 46.1315 - val_loss: 4063.4058 - val_root_mean_squared_error: 63.7408\n",
      "Epoch 3/100\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - loss: 2085.4443 - root_mean_squared_error: 45.1327 - val_loss: 3957.6792 - val_root_mean_squared_error: 62.9063\n",
      "Epoch 4/100\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - loss: 2305.1938 - root_mean_squared_error: 47.1961 - val_loss: 3629.2712 - val_root_mean_squared_error: 60.2396\n",
      "Epoch 5/100\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - loss: 2141.7107 - root_mean_squared_error: 45.7055 - val_loss: 4442.4336 - val_root_mean_squared_error: 66.6482\n",
      "Epoch 6/100\n",
      "\u001b[1m815/976\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2053.4963 - root_mean_squared_error: 44.6887"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# pruning_callback = TFKerasPruningCallback(trial, \"val_root_mean_squared_error\")\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Return validation RMSE as the score to minimize\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     val_rmse \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_root_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Last epoch RMSE\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/VSCode/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#mixed_precision.set_global_policy('mixed_float16')\n",
    "print(tf.test.is_built_with_cuda())  # Should return True\n",
    "print(tf.test.is_gpu_available())\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set TensorFlow to use only the first GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU enabled:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Define K for K-Fold Cross-Validation\n",
    "K = 5  # Number of folds\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)  # Ensure randomness\n",
    "\n",
    "# Store RMSE for each fold\n",
    "val_rmse_scores = []\n",
    "\n",
    "# Loop through K-folds\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):  # Assuming X_train, y_train are defined\n",
    "    print(f\"\\n Training Fold {fold+1}/{K}...\")\n",
    "    \n",
    "    X_train_sub, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_sub, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train_sub, y_train_sub))\n",
    "    train_dataset = train_dataset.batch(246).prefetch(tf.data.AUTOTUNE)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "   \n",
    "\n",
    "\n",
    "    model = keras.Sequential([\n",
    "         keras.layers.Input(shape=(X_train_sub.shape[1],)),\n",
    "        #  keras.layers.Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.005)),\n",
    "        #  keras.layers.Dropout(0.1),\n",
    "        #  keras.layers.Dense(256,activation='relu',kernel_regularizer=regularizers.l2(0.005)),\n",
    "        #  keras.layers.Dropout(0.1),\n",
    "          keras.layers.Dense(128,activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
    "        #  keras.layers.BatchNormalization(),\n",
    "          #keras.layers.Dropout(0.1),\n",
    "         keras.layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
    "         #keras.layers.BatchNormalization(),\n",
    "         #keras.layers.Dropout(0.1),\n",
    "         keras.layers.Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
    "         #keras.layers.BatchNormalization(), \n",
    "         #keras.layers.Dropout(0.3),\n",
    "         keras.layers.Dense(1, activation='linear')\n",
    "                                                      ])  # \n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# pruning_callback = TFKerasPruningCallback(trial, \"val_root_mean_squared_error\")\n",
    "\n",
    "    history = model.fit(train_dataset, \n",
    "                        epochs=100, \n",
    "                        verbose=1, validation_data=val_dataset)\n",
    "\n",
    "    # Return validation RMSE as the score to minimize\n",
    "    val_rmse = history.history['val_root_mean_squared_error'][-1]  # Last epoch RMSE\n",
    "    val_rmse_scores.append(val_rmse)  # Store RMSE score\n",
    "    print(f\"✅ Fold {fold+1} RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
